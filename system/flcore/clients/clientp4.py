import copy
import torch
import numpy as np
import time
import pandas as pd
from flcore.clients.clientbase import Client
from sklearn.preprocessing import label_binarize
from sklearn import metrics
from sklearn.metrics import roc_auc_score, average_precision_score
from sklearn.mixture import BayesianGaussianMixture
import matplotlib.pyplot as plt

class Clientp4(Client):
    def __init__(self, args, id, train_samples, test_samples, **kwargs):
        super().__init__(args, id, train_samples, test_samples, **kwargs)
        # p1
        self.p1_local_soft_labels = None  # æœ¬åœ°è½¯æ ‡ç­¾
        #æœ¬åœ°å„ä¸ªç±»åˆ«çš„æ•°é‡
        self.p1_local_nums_per_class = None
        self.kl_threshold=args.kl_threshold  # KLæ•£åº¦åˆ¤æœªçŸ¥çš„é˜ˆå€¼
        self.caculate_local_nums_per_class()
        print(f"P4Client {self.id} local nums per class: {self.p1_local_nums_per_class}")
        #print("\nClient p1 initialized.")

    def train(self,warmup=False):
        trainloader = self.load_train_data()
        # self.model.to(self.device)
        self.model.train()
        
        start_time = time.time()

        max_local_epochs = self.local_epochs
        if self.train_slow:
            max_local_epochs = np.random.randint(1, max_local_epochs // 2)


        #é¢„çƒ­é˜¶æ®µçš„è®­ç»ƒ
        if warmup:
            # print("warmup\n")
            for epoch in range(max_local_epochs):
                for i, (x, y) in enumerate(trainloader):
                    if type(x) == type([]):
                        x[0] = x[0].to(self.device)
                    else:
                        x = x.to(self.device)
                    y = y.to(self.device)
                    #print(y)
                    if self.train_slow:
                        time.sleep(0.1 * np.abs(np.random.rand()))
                    output = self.model(x)
                    # print("output before softmax:", output)
                    # print("y:", y)
                    loss = self.loss(output, y)
                    self.optimizer.zero_grad()
                    loss.backward()
                    self.optimizer.step()
        else:
            # print("normal train\n")
            for epoch in range(max_local_epochs):
                for i, (x, y) in enumerate(trainloader):
                    if type(x) == type([]):
                        x[0] = x[0].to(self.device)
                    else:
                        x = x.to(self.device)
                    y = y.to(self.device)
                    if self.train_slow:
                        time.sleep(0.1 * np.abs(np.random.rand()))
                    output = self.model(x)

                    loss = self.loss(output, y)
                    self.optimizer.zero_grad()
                    loss.backward()
                    self.optimizer.step()

        # self.model.cpu()

        if self.learning_rate_decay:
            self.learning_rate_scheduler.step()

        self.train_time_cost['num_rounds'] += 1
        self.train_time_cost['total_cost'] += time.time() - start_time
    

    # def compute_local_soft_labels(self):
    #     """
    #     è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æœ¬åœ°è½¯æ ‡ç­¾ï¼šå¯¹æœ¬åœ°è®­ç»ƒé›†æ¯ä¸ªç±»åˆ«ï¼Œç»Ÿè®¡å…¶ softmax æ¦‚ç‡çš„å‡å€¼
    #     """
    #     self.model.eval()
    #     trainloader = self.load_train_data()
    #     class_soft_labels = {}
    #     class_counts = {}

    #     with torch.no_grad():
    #         for x, y in trainloader:
    #             if type(x) == type([]):
    #                 x[0] = x[0].to(self.device)
    #             else:
    #                 x = x.to(self.device)
    #             y = y.to(self.device)
    #             outputs = self.model(x)
    #             probs = torch.softmax(outputs, dim=1)  # [batch, num_classes]
    #             for prob, label in zip(probs, y):
    #                 label = label.item()
    #                 if label not in class_soft_labels:
    #                     class_soft_labels[label] = prob.clone()
    #                     class_counts[label] = 1
    #                 else:
    #                     class_soft_labels[label] += prob
    #                     class_counts[label] += 1

    #     # å¯¹æ¯ä¸ªç±»åˆ«æ±‚å¹³å‡
    #     for label in class_soft_labels:
    #         class_soft_labels[label] /= class_counts[label]

    #     self.p1_local_soft_labels = class_soft_labels  # {label: mean_soft_label}
    #     #print(f"Client {self.id} computed local soft labels per class.")
    #     # for label, soft in class_soft_labels.items():
    #     #     print(f"Class {label}: {soft}")
    #     self.model.train()

    # def caculate_local_nums_per_class(self):
    #     """
    #     è®¡ç®—æœ¬åœ°æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡
    #     """
    #     trainloader = self.load_train_data()
    #     class_counts = {}

    #     for _, y in trainloader:
    #         for label in y:
    #             label = label.item()
    #             if label not in class_counts:
    #                 class_counts[label] = 1
    #             else:
    #                 class_counts[label] += 1
    #     self.p1_local_nums_per_class = class_counts 

    def compute_local_soft_labels(self):
        """
        è®¡ç®—å‰ 6 ä¸ªç±»åˆ«çš„æœ¬åœ°è½¯æ ‡ç­¾ï¼šå¯¹æœ¬åœ°è®­ç»ƒé›†æ¯ä¸ªç±»åˆ«ï¼Œç»Ÿè®¡å…¶ softmax æ¦‚ç‡çš„å‡å€¼
        """
        self.model.eval()
        trainloader = self.load_train_data()
        class_soft_labels = {}
        class_counts = {}

        with torch.no_grad():
            for x, y in trainloader:
                if type(x) == type([]):
                    x[0] = x[0].to(self.device)
                else:
                    x = x.to(self.device)
                y = y.to(self.device)
                outputs = self.model(x)
                probs = torch.softmax(outputs, dim=1)  # [batch, num_classes]
                for prob, label in zip(probs, y):
                    label = label.item()
                    if label >= 6:   # ğŸ‘ˆ è·³è¿‡ç¬¬ 6 ç±»ä¹‹åçš„ç±»åˆ«
                        continue
                    if label not in class_soft_labels:
                        class_soft_labels[label] = prob.clone()
                        class_counts[label] = 1
                    else:
                        class_soft_labels[label] += prob
                        class_counts[label] += 1

        # å¯¹æ¯ä¸ªç±»åˆ«æ±‚å¹³å‡
        for label in class_soft_labels:
            class_soft_labels[label] /= class_counts[label]

        self.p1_local_soft_labels = class_soft_labels  # {label: mean_soft_label}
        self.model.train()


    # p1
    # æ ¹æ®argmaxé€‰æ‹©ä¸å¯¹åº”ç±»çš„è½¯æ ‡ç­¾ï¼Œè®¡ç®—å…¶klæ•£åº¦ï¼Œå¤ªé«˜çš„å°±æ˜¯æœªçŸ¥ç±» å°±æ˜¯å‡å·²çŸ¥ç±»
    # è¿™æ ·çš„é€»è¾‘æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä¸ç”¨æ‹…å¿ƒè¯¯åˆ¤ï¼›åŸæœ¬å°±å·²ç»æ˜¯æœªçŸ¥ç±»äº†
    # åªè¦ä¸æ˜¯æœªçŸ¥ç±»ï¼Œå°±ä¸ä¼šè¯¯åˆ¤
    # def test_metrics(self,warmup=False):
            
    #         testloaderfull = self.load_test_data()
            
    #         self.model.eval()

    #         test_acc = 0
    #         test_num = 0
    #         y_prob = []
    #         y_true = []
            
    #         with torch.no_grad():
    #             for x, y in testloaderfull:
    #                 if type(x) == type([]):
    #                     x[0] = x[0].to(self.device)
    #                 else:
    #                     x = x.to(self.device)
    #                 # print("x type:", type(x), "x shape:", x.shape)
    #                 # print("y type:", type(y), "y shape:", y.shape)
    #                 y = y.to(self.device)
    #                 output = self.model(x)

    #                 if warmup:
    #                    test_acc += (torch.sum(torch.argmax(output, dim=1) == y)).item()
    #                 else:
    #                     #print("Client p1 test metrics with unknown detection.")
    #                      # éœ€è¦æ’å…¥è®¡ç®—klæ•£åº¦çš„ä»£ç 
    #                     kl_divs = self.compute_kl_divergence(output,y)
                       
    #                     # è®¾ç½®ä¸€ä¸ªé˜ˆå€¼ï¼Œå‡è®¾æ˜¯0.5ï¼Œè¶…è¿‡è¿™ä¸ªå€¼çš„æ ·æœ¬è¢«è®¤ä¸ºæ˜¯æœªçŸ¥ç±»
                        
    #                     preds = torch.argmax(output, dim=1)
    #                     preds[kl_divs > self.kl_threshold] = 6  # å‡è®¾æœªçŸ¥

    #                     test_acc += (torch.sum(preds == y)).item()
    #                 test_num += y.shape[0]
    
    #                 y_prob.append(output.detach().cpu().numpy())
    #                 nc = self.num_classes
    #                 if self.num_classes == 2:
    #                     nc += 1
    #                 # print("æµ‹è¯•aucçš„è®¡ç®—")
    #                 # print("self.num_classes:", nc)
    #                 # print("y:", y)

    #                 lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))
    #                 # print("lb:", lb)
    #                 # print("output:", output)
    #                 #lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))
    #                 if self.num_classes == 2:
    #                     lb = lb[:, :2]
    #                 y_true.append(lb)
                    

    #         # self.model.cpu()
    #         # self.save_model(self.model, 'model')

    #         y_prob = np.concatenate(y_prob, axis=0)
    #         y_true = np.concatenate(y_true, axis=0)

    #         auc = metrics.roc_auc_score(y_true, y_prob, average='micro')
    #         if warmup:
    #             return test_acc, test_num, auc
    #         else:
    #             unknown_test_status=self.unknown_test()
    #             return test_acc, test_num, auc, unknown_test_status

    def test_metrics(self, warmup=False):
        testloaderfull = self.load_test_data()
        self.model.eval()

        test_acc = 0
        test_num = 0
        y_prob = []
        y_true = []

        with torch.no_grad():
            for x, y in testloaderfull:
                if isinstance(x, list):
                    x[0] = x[0].to(self.device)
                else:
                    x = x.to(self.device)
                y = y.to(self.device)
                output = self.model(x)

                preds = torch.argmax(output, dim=1)  # æ¨¡å‹é¢„æµ‹ç±»åˆ«

                if warmup:
                    test_acc += (preds == y).sum().item()
                else:
                    # ---- åªå¯¹éæœ€åä¸€ç±»è®¡ç®— KL æ•£åº¦ ----
                    kl_divs = self.compute_kl_divergence(output, y).to(self.device)

                    # åˆ›å»ºä¸€ä¸ª maskï¼Œåªå¯¹éæœ€åä¸€ç±»æ ·æœ¬åˆ¤æ–­æœªçŸ¥
                    last_class = self.num_classes - 1
                    mask = preds != last_class  # True è¡¨ç¤ºéœ€è¦æ£€æµ‹æœªçŸ¥

                    # ä»…å¯¹ mask ä½ç½®çš„æ ·æœ¬åº”ç”¨é˜ˆå€¼è§„åˆ™
                    #print(mask)
                    #print(kl_divs)
                    preds[mask & (kl_divs > self.kl_threshold)] = 6  # åˆ¤æœªçŸ¥ç±»ä¸ºæœ€åä¸€ç±»

                    test_acc += (preds == y).sum().item()

                test_num += y.size(0)

                y_prob.append(output.detach().cpu().numpy())
                nc = self.num_classes
                if self.num_classes == 2:
                    nc += 1

                lb = label_binarize(y.detach().cpu().numpy(), classes=np.arange(nc))
                if self.num_classes == 2:
                    lb = lb[:, :2]
                y_true.append(lb)

        y_prob = np.concatenate(y_prob, axis=0)
        y_true = np.concatenate(y_true, axis=0)
        auc = metrics.roc_auc_score(y_true, y_prob, average='micro')

        if warmup:
            return test_acc, test_num, auc
        else:
            unknown_test_status = self.unknown_test()
            return test_acc, test_num, auc, unknown_test_status

    def caculate_local_nums_per_class(self):
        """
        è®¡ç®—æœ¬åœ°æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡
        """
        trainloader = self.load_train_data()
        class_counts = {}

        for _, y in trainloader:
            for label in y:
                label = label.item()
                if label not in class_counts:
                    class_counts[label] = 1
                else:
                    class_counts[label] += 1
        self.p1_local_nums_per_class = class_counts


    # æ ¹æ®yçš„argmaxå»è®¡ç®—klæ•£åº¦
    def compute_kl_divergence(self, outputs, y):
        """
        è®¡ç®—è¾“å‡ºä¸å¯¹åº”ç±»çš„è½¯æ ‡ç­¾ä¹‹é—´çš„ KL æ•£åº¦
        outputs: æ¨¡å‹çš„åŸå§‹è¾“å‡º logitsï¼Œå½¢çŠ¶ä¸º [batch_size, num_classes] 
        è¿”å›ï¼šæ¯ä¸ªæ ·æœ¬çš„ KL æ•£åº¦ï¼Œå½¢çŠ¶ä¸º [batch_size]
        """
        probs = torch.softmax(outputs, dim=1)  # è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ
        kl_divs = []

        for prob ,yy in zip(probs,y):
            label = torch.argmax(prob).item()
            
            if (self.p1_local_soft_labels is not None and 
                label in self.p1_local_soft_labels):
                soft_label = self.p1_local_soft_labels[label].to(self.device)
                kl_div = torch.sum(soft_label * (torch.log(soft_label + 1e-10) - torch.log(prob + 1e-10)))
                kl_divs.append(kl_div.item())
            else:
                # å¦‚æœè¯¥ç±»åˆ«æ²¡æœ‰è½¯æ ‡ç­¾ï¼Œè®¾å®šä¸€ä¸ªè¾ƒé«˜çš„ KL æ•£åº¦å€¼ï¼Œè¡¨ç¤ºä¸ç¡®å®š
                kl_divs.append(float('inf'))
            #print("Predicted label:", label, "true y", yy, "KL Divergence:", kl_div)
        

        return torch.tensor(kl_divs)


    # def unknown_test(self):
    #     testloader = self.load_test_data()
    #     self.model.eval()
        
    #     known_correct = 0
    #     known_total = 0
    #     unk_correct = 0
    #     unk_total = 0
    #     all_labels = []
    #     all_probs = []
    #     all_kl = []

    #     # kl_threshold = 0.4 # KLæ•£åº¦åˆ¤æœªçŸ¥çš„é˜ˆå€¼

    #     with torch.no_grad():
    #         for i, (x, y) in enumerate(testloader):
    #             if type(x) == type([]):
    #                 x[0] = x[0].to(self.device)
    #             else:
    #                 x = x.to(self.device)
    #             y = y.to(self.device)
    #             outputs = self.model(x)

    #             # è®¡ç®—KLæ•£åº¦
    #             kl_divs = self.compute_kl_divergence(outputs, y)
    #             preds = torch.argmax(outputs, dim=1)
    #             preds[kl_divs > self.kl_threshold] = 6  # KLå¤§äºé˜ˆå€¼çš„ç›´æ¥åˆ¤ä¸ºæœªçŸ¥

    #             # åŒºåˆ†å·²çŸ¥ç±»å’ŒæœªçŸ¥ç±»
    #             known_mask = (y >= 0) & (y < 6)
    #             unknown_mask = (y == 6)

    #             # å·²çŸ¥ç±»é¢„æµ‹
    #             known_correct += ((preds == y) & known_mask).sum().item()
    #             known_total += known_mask.sum().item()

    #             # æœªçŸ¥ç±»æ£€æµ‹
    #             unk_correct += ((preds == 6) & unknown_mask).sum().item()
    #             unk_total += unknown_mask.sum().item()

    #             all_labels.extend(y.cpu().numpy())
    #             all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())
    #             all_kl.extend(kl_divs.cpu().numpy())

    #     # è®¡ç®—OS*å’ŒUNK
    #     os_star = 100.0 * known_correct / known_total if known_total > 0 else 0.0
    #     unk_acc = 100.0 * unk_correct / unk_total if unk_total > 0 else 0.0
    #     hos = 2 * (os_star * unk_acc) / (os_star + unk_acc + 1e-8) if (os_star + unk_acc) > 0 else 0.0

    #     # ---- AUROC & AUPR è®¡ç®— ----
    #     all_labels = np.array(all_labels)
    #     all_kl = np.array(all_kl)

    #     # æœªçŸ¥ç±»ä¸º1ï¼Œå·²çŸ¥ç±»ä¸º0
    #     is_unknown = (all_labels == 6).astype(int)

    #     # KLè¶Šå¤§è¶Šå¯èƒ½æœªçŸ¥
    #     try:
    #         auroc_kl = roc_auc_score(is_unknown, all_kl)
    #         aupr_kl = average_precision_score(is_unknown, all_kl)
    #     except ValueError:
    #         print('Only one class present in y_true. AUROC and AUPR are undefined.')
    #         auroc_kl, aupr_kl = np.nan, np.nan
    #     print("-------------------------------------------")
    #     print(f"[KL-divergence] AUROC: {auroc_kl:.4f}, AUPR: {aupr_kl:.4f}")
    #     print("===========================================\n")

    #     return known_correct, known_total, unk_correct, unk_total, os_star, unk_acc, hos


    def unknown_test(self):
        testloader = self.load_test_data()
        self.model.eval()

        known_correct = 0
        known_total = 0
        unk_correct = 0
        unk_total = 0
        all_labels = []
        all_probs = []
        all_kl = []

        last_class = self.num_classes - 1  # æœ€åä¸€ç±»ï¼ˆæœªçŸ¥ç±»ï¼‰

        with torch.no_grad():
            for i, (x, y) in enumerate(testloader):
                if isinstance(x, list):
                    x[0] = x[0].to(self.device)
                else:
                    x = x.to(self.device)
                y = y.to(self.device)
                outputs = self.model(x)

                preds = torch.argmax(outputs, dim=1)

                # ---- åªå¯¹éæœ€åä¸€ç±»é¢„æµ‹æ ·æœ¬è®¡ç®— KL æ•£åº¦ ----
                kl_divs = torch.zeros_like(preds, dtype=torch.float32, device=self.device)
                #kl_divs = kl_divs.to(self.device)
                non_last_mask = preds != last_class  # True è¡¨ç¤ºä¸æ˜¯æœ€åä¸€ç±»çš„æ ·æœ¬
                #non_last_mask = non_last_mask.to(self.device)
                #print(non_last_mask)
                #print(kl_divs)
                if non_last_mask.any():
                    kl_partial = self.compute_kl_divergence(outputs[non_last_mask], y[non_last_mask])
                    kl_divs[non_last_mask] = kl_partial.to(self.device)

                    # ä»…å¯¹è¿™äº›æ ·æœ¬åº”ç”¨ KL é˜ˆå€¼è§„åˆ™
                    preds[non_last_mask & (kl_divs > self.kl_threshold)] = last_class

                # ---- åŒºåˆ†å·²çŸ¥ / æœªçŸ¥ç±» ----
                known_mask = (y >= 0) & (y < last_class)
                unknown_mask = (y == last_class)

                # å·²çŸ¥ç±»é¢„æµ‹å‡†ç¡®ç‡
                known_correct += ((preds == y) & known_mask).sum().item()
                known_total += known_mask.sum().item()

                # æœªçŸ¥ç±»æ£€æµ‹å‡†ç¡®ç‡
                unk_correct += ((preds == last_class) & unknown_mask).sum().item()
                unk_total += unknown_mask.sum().item()

                # è®°å½•åˆ†ææ•°æ®
                all_labels.extend(y.cpu().numpy())
                all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())
                all_kl.extend(kl_divs.cpu().numpy())

        # ---- æŒ‡æ ‡è®¡ç®— ----
        os_star = 100.0 * known_correct / known_total if known_total > 0 else 0.0
        unk_acc = 100.0 * unk_correct / unk_total if unk_total > 0 else 0.0
        hos = 2 * (os_star * unk_acc) / (os_star + unk_acc + 1e-8) if (os_star + unk_acc) > 0 else 0.0

        # ---- AUROC & AUPR è®¡ç®— ----
        all_labels = np.array(all_labels)
        all_kl = np.array(all_kl)
        is_unknown = (all_labels == last_class).astype(int)  # æœªçŸ¥ç±»ä¸º1

        try:
            auroc_kl = roc_auc_score(is_unknown, all_kl)
            aupr_kl = average_precision_score(is_unknown, all_kl)
        except ValueError:
            print('Only one class present in y_true. AUROC and AUPR are undefined.')
            auroc_kl, aupr_kl = np.nan, np.nan

        print("-------------------------------------------")
        print(f"[KL-divergence] AUROC: {auroc_kl:.4f}, AUPR: {aupr_kl:.4f}")
        print("===========================================\n")

        return known_correct, known_total, unk_correct, unk_total, os_star, unk_acc, hos





    # è‡ªåŠ¨è®¾ç½®klé˜ˆå€¼ DPGMM
    def dpgmm_cluster(self, kl_values, show_plot=False):
        """
        ä½¿ç”¨ DPGMM å¯¹ KL æ•£åº¦è¿›è¡Œèšç±»ï¼Œå¹¶åŒºåˆ†å·²çŸ¥/æœªçŸ¥ç±»ã€‚
        è¿”å›ï¼šQï¼ˆ0=æœªçŸ¥ï¼Œ1=å·²çŸ¥ï¼‰
        """
        kl_values = kl_values.reshape(-1, 1)
        dpgmm = BayesianGaussianMixture(
            n_components=2,      # æœ€å¤§æ··åˆæ•°é‡ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨è°ƒèŠ‚
            covariance_type='full',
            weight_concentration_prior_type='dirichlet_process',
            max_iter=500,
            random_state=42
        )
        dpgmm.fit(kl_values)
        Q = dpgmm.predict(kl_values)

        # ----------------- å¯è§†åŒ–éƒ¨åˆ† -----------------
        if show_plot:
            xs = np.linspace(np.min(kl_values), np.max(kl_values), 500).reshape(-1, 1)
            logprob = dpgmm.score_samples(xs)
            responsibilities = dpgmm.predict_proba(xs)
            pdf = np.exp(logprob)

            plt.figure(figsize=(8, 4))
            plt.hist(kl_values, bins=40, density=True, alpha=0.5, label='KL values')
            plt.plot(xs, pdf, '-k', label='DPGMM total PDF')

            for i, comp in enumerate(responsibilities.T):
                plt.plot(xs, comp * pdf, '--', label=f'Component {i}')

            plt.title("DPGMM Fit on KL Divergences")
            plt.xlabel("KL Divergence")
            plt.ylabel("Density")
            plt.legend()
            plt.show()

            # è¾“å‡ºå„é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼ä¸æ–¹å·®ï¼Œæ–¹ä¾¿åˆ†æ
            print("DPGMM component means:", dpgmm.means_.flatten())
            print("DPGMM component variances:", np.array([np.diag(cov)[0] for cov in dpgmm.covariances_]))

        # ----------------- ç°‡åˆ¤æ–­é€»è¾‘ -----------------
        # å‡è®¾ KL è¾ƒå°çš„ä¸€ç°‡ä¸ºå·²çŸ¥ç±»
        means = dpgmm.means_.flatten()
        known_cluster = np.argmin(means)
        Q_binary = np.array([1 if q == known_cluster else 0 for q in Q])

        return Q_binary